{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhoomikadayal/Mobile_price_project/blob/main/Mobile_price_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Project Name**    - Mobile Price Range Prdiction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "##### **Project Type**    - Classifiaction\n",
        "##### **Contribution**    - TEAM \n",
        "##### **Team Name** - TEAM DENVER\n",
        "##### **Team Member 1 -**  Sumit Ghanghas   \n",
        "##### **Team Member 2 -**  Bhoomika Dhayal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6K7xa23Elo4"
      },
      "source": [
        "# **GitHub Link -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1o69JH3Eqqn"
      },
      "source": [
        "##### **Team Member 1 -**  Sumit Ghanghas \n",
        "https://github.com/ghanghas291/mobile-price-prediction\n",
        "##### **Team Member 2 -**  Bhoomika Dhayal\n",
        "https://github.com/Bhoomikadayal/Mobile_price_project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "#### Mobile phones have become a necessity for every individual person. People want more features and best specifications in a phone  at cheaper prices.\n",
        "#### Mobile phones come in all sorts of prices, features, specifications and all. Price estimation and prediction is an important part of consumer strategy by a company. Deciding the correct price of a product is very important for the market success of that product. A new product that has to be launched must have the correct price so that consumers wants to buy the product.\n",
        "#### In the competitive  market, companies want to understand sales data of mobile phones and factors which drive the prices. The objective is to find out some relation between features of a mobile phone (e.g.:- RAM, Internal Memory, etc) and its selling price. In this problem, we do not have to predict the actual price but a price range indicating how high the price is.\n",
        "#### The main objective of this project is to build a model which will classify the price range of mobile phones based on the specifications of mobile phones.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhDvGCAqmjP1"
      },
      "source": [
        "# **Business Understanding**\n",
        "\n",
        "**In the competitive mobile phone market companies want to understand sales data of mobile phones and factors which drive the prices.The objective is to find out some relation between features of a mobile phone(eg:- RAM,Internal Memory, etc) and its selling price. In this problem, we do not have to predict theactual price but a price range indicating how high the price is.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "* **Battery_power** - Total energy of a battery can store  in unit(mAh)\n",
        "* **Blue** - Has bluetooth or not\n",
        "* ***Clock_speed*** - speed at which microprocessor executes instructions\n",
        "* ***Dual_sim*** - Has dual sim support or not\n",
        "* ***Fc*** - Front Camera in mega pixels\n",
        "* ***Four_g*** - Has 4G or not\n",
        "* ***Int_memory*** - Internal Memory in Gigabytes\n",
        "* ***M_dep*** - Mobile Depth in cm\n",
        "* ***Mobile_wt*** - Weight of mobile phone\n",
        "* ***N_cores*** - Number of cores of processor\n",
        "* ***Pc*** - Primary Camera mega pixels\n",
        "* ***Px_height*** - Pixel Resolution Height\n",
        "* ***Px_width*** - Pixel Resolution Width\n",
        "* ***Ram*** - Random Access Memory in Mega Bytes\n",
        "* ***Sc_h*** - Screen Height of mobile in cm\n",
        "* ***Sc_w*** - Screen Width of mobile in cm\n",
        "* ***Talk_time*** - longest time that a single battery charge will last when you are\n",
        "* ***Three_g*** - Has 3G or not\n",
        "* ***Touch_screen*** - Has touch screen or not\n",
        "* ***Wifi*** - Has wifi or not\n",
        "* ***Price_range*** - This is the target variable with value of \n",
        "* 0(low cost), \n",
        "* 1(medium cost),\n",
        "* 2(high cost) and\n",
        "* 3(very high cost).\n",
        "* Thus our target variable has 4 categories so basically it is a Multiclass classification problem.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_i_v8NEhb9l"
      },
      "source": [
        "# ***Let's Begin !***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhfV-JJviCcP"
      },
      "source": [
        "## ***1. Know Your Data***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading from google drive and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCmkjMzChHk6"
      },
      "outputs": [],
      "source": [
        "# mount the dataset from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from datetime import datetime\n",
        "import datetime as dt\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E0lQxpa0cwj"
      },
      "outputs": [],
      "source": [
        "# load the data set from drive\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/casptone project - 3 (Classification)/data_mobile_price_range.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x71ZqKXriCWQ"
      },
      "source": [
        "### Dataset First View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "outputs": [],
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0iJBH69y6oi"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBIi_osiCS2"
      },
      "source": [
        "### Dataset Rows & Columns count\n",
        "it tells us that there is 2000 rows and 21 columns in that dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "outputs": [],
      "source": [
        "# Dataset Rows & Columns count\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlHwYmJAmNHm"
      },
      "source": [
        "### Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "outputs": [],
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYCXwxTfhHlA"
      },
      "source": [
        "There is no null values in that dataset. That is the best thing in that data it saves too much time in real time dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-RD77Z1hHlB"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35m5QtbWiB9F"
      },
      "source": [
        "#### Duplicate Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "outputs": [],
      "source": [
        "# Dataset Duplicate Value Count\n",
        "a = df.duplicated().sum()\n",
        "print(f\"the duplicates values in data is {a}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0kj-8xxnORC"
      },
      "source": [
        "### What did you know about your dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfoNAAC-nUe_"
      },
      "source": [
        "We found that there is no duplicates values in that data set and no null values that makes easy for prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      },
      "source": [
        "## ***2. Understanding Your Variables***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "outputs": [],
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "outputs": [],
      "source": [
        "# Dataset Describe (Looking for the description of the dataset to get insights of the data)\n",
        "df.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTbrJXOngz2"
      },
      "source": [
        "### Variables Description "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJV4KIxSnxay"
      },
      "source": [
        "* This Dataset contains 2000 lines and 21 columns.*** \n",
        "* We can see that sc_width and px_height has minimum value 0. which is not possible in any mobile. We need to handle this mismatch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-AO7VtD0cwq"
      },
      "outputs": [],
      "source": [
        "# Checking How many observations having screen width value as 0.\n",
        "print(df[df['sc_w']==0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ooubllbk0cwr"
      },
      "outputs": [],
      "source": [
        "# Checking How many observations having px_hieght value as 0.\n",
        "print(df[df['px_height']==0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tk4eyZQa0cwr"
      },
      "outputs": [],
      "source": [
        "# As there are only 2 observations having px_height=0. so we will drop it.\n",
        "df=df[df['px_height']!=0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJwOSsLB0cwr"
      },
      "source": [
        "## Nearest Neighbors Imputations (KNNImputer)\n",
        "\n",
        "Missing values are imputed using the k-Nearest Neighbors approach where a Euclidean distance is used to find the nearest neighbors.\n",
        "\n",
        "Letâ€™s take the above example of the titanic dataset to see how it works.\n",
        "* Before using KNN Imputer we need to replace 0 with NAN values. so that it will work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyRG-91y0cws"
      },
      "outputs": [],
      "source": [
        "# Replacing 0 with NAN so that we can implement KNN Imputer.\n",
        "df['sc_w']=df['sc_w'].replace(0,np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAGow1I50cws"
      },
      "outputs": [],
      "source": [
        "# import KNN imputer frio sklearn\n",
        "from sklearn.impute import KNNImputer\n",
        "impute_knn = KNNImputer(n_neighbors=1)\n",
        "df=pd.DataFrame(impute_knn.fit_transform(df),columns=df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbaYkeRN0cwt"
      },
      "outputs": [],
      "source": [
        "# Checking shape\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hovtJKtx0cwt"
      },
      "outputs": [],
      "source": [
        "# Checking How many observations having sc_w value as 0.\n",
        "df[df['sc_w']==0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGf3EUSr0cwu"
      },
      "source": [
        "**Thus we have handled the mismatched values of the data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "outputs": [],
      "source": [
        "# Checking the datatypes, non null values\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_CTpDwl0cwu"
      },
      "source": [
        "##### it is showing 1998  because we drop 2 rows "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbyXE7I1olp8"
      },
      "source": [
        "We don't found any null values and no duplicates values  so it's clear that the data is neat and clean for visualizating and ready fot visualizating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF8Ens_Soomf"
      },
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UPI53ET0cwv"
      },
      "source": [
        "### **Let's have look at target variable first.!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkPgyCKk0cwv"
      },
      "outputs": [],
      "source": [
        "# lets have look at our target variable's counts\n",
        "price_range_values=df['price_range'].value_counts()\n",
        "price_range_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llNdQ14l0cwv"
      },
      "source": [
        "\n",
        "***This is the target variable with value of***\n",
        "* ***0=low cost,***\n",
        "* ***1=medium cost,***\n",
        "* ***2=high cost,***\n",
        "* ***3=very high cost.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B8jpwQ_0cww"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOQAZs5pc--"
      },
      "source": [
        "#### Chart - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "outputs": [],
      "source": [
        "# Visualizing the Target variable's class distribution.\n",
        "fig,ax=plt.subplots(figsize=(5,5))\n",
        "labels = [\"low cost\", \"medium cost\", \"high cost\", \"very high cost\"]\n",
        "price_range_values.plot.pie(explode=[0.05]*4,labels=labels,autopct='%1.1f%%',figsize=(12,8),ax=ax,fontsize=15)    # plotting pie chart\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESiWehPqBRc"
      },
      "source": [
        "#### We can see that our target varibale is equally distributed.Thus we don't have to worry about data imbalance and there is no need of oversampling or undersampling.Which is good for us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSlN3yHqYklG"
      },
      "source": [
        "#### Chart - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "outputs": [],
      "source": [
        "# Chart - 2 visualization code\n",
        "fig,ax=plt.subplots(figsize=(4,4))\n",
        "sns.countplot(x=df['price_range'],ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wYz4tCohHlP"
      },
      "source": [
        "####  conclusion : From the above count plot chart total 2000 dataset.I got to know that, there are 500 mobile data which are low cost, 500 mobile data which are medium cost, 500 mobile data which are high cost and 500 mobile data which are very high cost of the whole mobile data given in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM7whBJCYoAo"
      },
      "source": [
        "#### Chart - 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "outputs": [],
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(8,8))\n",
        "rows=3\n",
        "col=3\n",
        "count=1\n",
        "var_list=['blue','dual_sim','four_g','three_g','wifi','touch_screen']\n",
        "labels=['Yes','No']\n",
        "for var in var_list:\n",
        "  plt.subplot(rows,col,count)\n",
        "  df[var].value_counts().plot.pie(autopct='%1.1f%%',fontsize=12,labels=labels)\n",
        "  plt.title(f'has {var} or not',fontsize=14)\n",
        "  plt.tight_layout()\n",
        "  count=count+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UADHo0k_0cwy"
      },
      "source": [
        "#### 1 means it has the specifications\n",
        "#### 0 means it do not have the specifications\n",
        "#### Percentage Distribution of Mobiles having bluetooth,dual sim, 4G,wifi and touchscreen are almost 50 %\n",
        "#### very few mobiles(23.8%) do not have Three_g\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMS40X0O0cwy"
      },
      "source": [
        "# **Categorical data and numerical data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbACIIfk0cwy"
      },
      "outputs": [],
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# numeric col list\n",
        "numeric_col=['battery_power','clock_speed','fc','int_memory','m_dep','mobile_wt','n_cores','pc','px_height',\n",
        "             'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time',]\n",
        "\n",
        "data_cat = df[['blue','dual_sim', 'four_g','three_g','touch_screen', 'wifi']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bamQiAODYuh1"
      },
      "source": [
        "#### Chart - 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "outputs": [],
      "source": [
        "binary_features = [ 'four_g', 'three_g']\n",
        "\n",
        "# Chart - 6 visualization code\n",
        "# Plot of binary features against price range\n",
        "\n",
        "for col in binary_features:\n",
        "  fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize = (10, 5))\n",
        "\n",
        "  df[col].value_counts().plot.pie (autopct='%1.1f%%', ax = ax1, shadow=True, labeldistance=None)\n",
        "  ax1.set_title('Distribution by price range')\n",
        "  ax1.legend(['Support', 'Does not Support'])\n",
        "  sns.countplot(x = col, hue = 'price_range', data = df, ax = ax2, color = 'pink')\n",
        "  ax2.set_title('Distribution by price range')\n",
        "  ax2.set_xlabel(col)\n",
        "  ax2.legend(['Low Cost', 'Medium Cost', 'High Cost', 'Very High Cost'])\n",
        "  ax2.set_xticklabels(['Does not Support', 'Support'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9I_v2Q5hHlT"
      },
      "source": [
        "#### conclusion : 3g has supported by 24 % more as compare to 4g mobiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH-pJp9IphqM"
      },
      "source": [
        "#### Chart - 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "outputs": [],
      "source": [
        "# Chart - 6 visualization code\n",
        "fig,ax=plt.subplots(figsize=(5,5))\n",
        "sns.boxplot(x=\"price_range\", y=\"battery_power\", data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIx-8_IphqN"
      },
      "source": [
        "#### Chart - 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "outputs": [],
      "source": [
        "# numeric col list\n",
        "numeric_col=['battery_power','clock_speed','fc','int_memory','m_dep','mobile_wt','n_cores','pc','px_height',\n",
        "             'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time',]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfYLBTWK0cw5"
      },
      "outputs": [],
      "source": [
        "# plotting boXplot and distribution\n",
        "for var in numeric_col:\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    fig = sns.boxplot(y=df[var],color='red')\n",
        "    fig.set_title('')\n",
        "    fig.set_ylabel(var)\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    fig = sns.distplot(df[var],color='red')\n",
        "    \n",
        "    fig.set_xlabel(var)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvSq8iUTphqO"
      },
      "source": [
        "* Data is well distrubted.\n",
        "* fc and px_height has some outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D-SW8Y40cw6"
      },
      "source": [
        "#  Remove Outlier ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNxf9uSd0cw6"
      },
      "outputs": [],
      "source": [
        "Q1 = df[\"fc\"].quantile(0.25)\n",
        "Q3 = df['fc'].quantile(0.991)\n",
        "IQR = Q3-Q1\n",
        "\n",
        "# Outliers are present after Quartile 3. so we will take datapoints before Q3.\n",
        "df = df[(df['fc'] <= Q3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mz8udtHJ0cw7"
      },
      "outputs": [],
      "source": [
        "\n",
        "Q1 = df[\"px_height\"].quantile(0.25)\n",
        "Q3 = df['px_height'].quantile(0.991)\n",
        "IQR = Q3-Q1\n",
        "# Outliers are present after Quartile 3. so we will take datapoints before Q3.\n",
        "df = df[(df['px_height'] <= Q3)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zuks4s_E0cw7"
      },
      "source": [
        "### Checking again outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu2HatJZ0cw7"
      },
      "outputs": [],
      "source": [
        "# Visualising whether oultliers are removed or not.\n",
        "for var in ['fc','px_height']:\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    fig = sns.boxplot(y=df[var],color='green')\n",
        "    fig.set_title('')\n",
        "    fig.set_ylabel(var)\n",
        "    \n",
        "    plt.subplot(1, 2, 2)\n",
        "    fig = sns.distplot(df[var],color='green')\n",
        "    \n",
        "    fig.set_xlabel(var)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeH3gUGU0cw8"
      },
      "source": [
        "#### there is no outlier in data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tM09qPYz0cw8"
      },
      "outputs": [],
      "source": [
        "# create copy of mobile_data\n",
        "df1=df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFkkMReAhHlj"
      },
      "source": [
        "## **Check Correlation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JqJn1KrhHlj"
      },
      "outputs": [],
      "source": [
        "df.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC_X3p0fY2L0"
      },
      "source": [
        "#### Chart - 10 - Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "outputs": [],
      "source": [
        "corr= df.corr()\n",
        "plt.figure(figsize=(25,10))\n",
        "sns.heatmap(corr,annot=True, cmap=plt.cm.Accent_r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcGeiVX5hHlo"
      },
      "source": [
        "# **Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wygRK7chHlp"
      },
      "source": [
        "### **1. Train Test split for regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co-L3cdThHlp"
      },
      "source": [
        "Before fitting any model, it is best to divide the dataset into two parts: training and testing. This means that 80% goes toward training the model, some portion will be used to check that our model is performing on any unseen data, and 20% is set aside for testing. In this step, we will split our data into training and testing sets using the Scikit-Learn library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xOFwTkOhHlp"
      },
      "outputs": [],
      "source": [
        "# independent variables.\n",
        "X=df[['ram','px_height','battery_power','px_width','mobile_wt','int_memory','sc_h','talk_time','sc_w','fc','n_cores','pc']]\n",
        "\n",
        "# dependent varaible\n",
        "y=df['price_range']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcZBKBY9hHlp"
      },
      "outputs": [],
      "source": [
        "X.head()   # here we check that our data is split proper or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0em-I3gohHlp"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elTynOydhHlq"
      },
      "source": [
        "#### train and test data split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z24SEt7LhHlq"
      },
      "outputs": [],
      "source": [
        "# splitting the data into Train and test data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt81Nhff0cxC"
      },
      "source": [
        "\n",
        "\n",
        "# Predictive Modeling:\n",
        "Algorithms used for predictive modeling:\n",
        "* 1) Decision Tree\n",
        "* 2) Random Forest classifier\n",
        "* 3) K-nearest Neighbour classifier\n",
        "* 4) Support Vector Machine(SVM)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5xXfads0cxC"
      },
      "source": [
        "**As Decision tree,random forest and enssembles trees do not require Feature scaling as these are Tree based models. So we will be using X_train and X_test which are not scaled.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWOQW4Sh0cxC"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Scaling the data.\n",
        "# creating an object of MinMax Scaler\n",
        "scaler=StandardScaler()\n",
        "X_train_scaled=scaler.fit_transform(X_train)   # fitting the X_train\n",
        "X_test_scaled=scaler.transform(X_test)         # transforming X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41fZp0i-0cxD"
      },
      "outputs": [],
      "source": [
        "# creating a class list\n",
        "Class_cat = ['low cost','medium cost', 'high cost', 'very high cost']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz44LaxlhHlu"
      },
      "source": [
        "# **1)Decision Tree Classifier:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sb0aS47hHlu"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# Creating object of the decision tree.\n",
        "dtc=DecisionTreeClassifier(random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sqiTzr_hHlv"
      },
      "outputs": [],
      "source": [
        "# fitting/training the train set.\n",
        "dtc.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlg0qvs50cxH"
      },
      "outputs": [],
      "source": [
        "# Predicting y values of train and test data.\n",
        "y_train_pred=dtc.predict(X_train)\n",
        "y_pred=dtc.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m8lSRsc0cxH"
      },
      "outputs": [],
      "source": [
        "# Checking train set accuracy.\n",
        "accuracy_score(y_train,y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNnUu1dF0cxI"
      },
      "outputs": [],
      "source": [
        "# Checking test set accuracy\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMUbhoXM0cxI"
      },
      "source": [
        "* ***Train set accuracy is 100% and test accuracy is 84%.***\n",
        "* ***Model is overfitted on train set and did not generalised well.***\n",
        "* ***We will tune hyperparamters to reduce overfitting and try to imporve the model performance.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wlCGtuk0cxI"
      },
      "source": [
        "### **Let's tune some hypereparameters of Decsion Tree classifier:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgrUmLU60cxI"
      },
      "outputs": [],
      "source": [
        "# creating an object of classifier.\n",
        "dtc_= DecisionTreeClassifier(random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxLSOnG70cxJ"
      },
      "outputs": [],
      "source": [
        "# paramter grid values for hyperparameter tunning.\n",
        "grid_values={'criterion':['gini','entropy'],\n",
        "             'max_depth':[2,3,4,5,6,9,10,11,12,13,14,15],\n",
        "             'splitter':['best','random'],\n",
        "             'min_samples_split':[3,5,10],\n",
        "             'max_features':['auto','sqrt','log2',None]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a5Z6OE50cxJ"
      },
      "outputs": [],
      "source": [
        "# applying GridSearchCv and fitting the model with it.\n",
        "dtc_tune=GridSearchCV(dtc_,param_grid=grid_values,cv=5,scoring='accuracy',verbose=3)\n",
        "dtc_tune.fit(X_train,y_train)   # model fitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQV5uPjH0cxJ"
      },
      "outputs": [],
      "source": [
        "# getting best parameters for model.\n",
        "dtc_tune.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B2tefta0cxJ"
      },
      "outputs": [],
      "source": [
        "# getting best estimators\n",
        "dtc_tune.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpz8gUe00cxK"
      },
      "outputs": [],
      "source": [
        "# using best parameters and training the the data.\n",
        "dtc_optimal=DecisionTreeClassifier(criterion='entropy', max_depth=9, min_samples_split=10,\n",
        "                       random_state=0)\n",
        "dtc_optimal.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EYjn6rE0cxK"
      },
      "outputs": [],
      "source": [
        "# predicting y values of train and test set.\n",
        "y_train_pred=dtc_optimal.predict(X_train)\n",
        "y_pred=dtc_optimal.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzH4xVfP0cxK"
      },
      "outputs": [],
      "source": [
        "# Checking the accuarcy score of train set.\n",
        "accuracy_score(y_train,y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGfE7Kmu0cxK"
      },
      "outputs": [],
      "source": [
        "# Checking the accuarcy score of test set.\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWcp_7Wq0cxL"
      },
      "source": [
        "### **Decision Tree Classifier-Observations:**\n",
        "* ***Train accuarcy has been reduced to 98% from 100% and test accuarcy is increased by 1% . Thus we somewhat reduced the overfiiting by reducing the training accuarcy. However this will not be good model for us.***\n",
        "\n",
        "* ***RAM,battery power,px_height and width came out to be the most important featrures***\n",
        "* ***This model classified the class 0 and class 3 very nicely as we can see the AUC is almost 0.96 for both classes,whereas for class 1 and class 2 it is 0.88.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqOdY6KG0cxL"
      },
      "source": [
        "# **2) Random Forest classifier:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tpm02P60cxM"
      },
      "source": [
        "### **With default hyperparamters:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCx6Yde30cxM"
      },
      "outputs": [],
      "source": [
        "# splitting the data into trainset and test set.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QeEK1xaC0cxM"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import  RandomForestClassifier\n",
        "# creating an object of the classifier.\n",
        "rfc=RandomForestClassifier(random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrhubJMz0cxN"
      },
      "outputs": [],
      "source": [
        "# fitting/training the model.\n",
        "rfc.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8STMUTC_0cxO"
      },
      "outputs": [],
      "source": [
        "# predicting the y values of train set and test set.\n",
        "y_train_pred=rfc.predict(X_train)\n",
        "y_pred=rfc.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEBQDKHq0cxO"
      },
      "outputs": [],
      "source": [
        "# Checking the accuarcy score of train set.\n",
        "accuracy_score(y_train,y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ongvoBh70cxO"
      },
      "outputs": [],
      "source": [
        "# Checking the accuracy score of test set.\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAXK1Mz70cxO"
      },
      "source": [
        "* ***Train accuarcy is 100% and test accuracy is 88%. which is quite good. But model seems to be overfitted and has not generalised the data well. We need to reduce overfitting and improve the model performance.***\n",
        "* ***we do some hyperparameter tunning to reduce overfitting***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwOxdZ-_0cxP"
      },
      "source": [
        "### **Let's do some Hyperparamter Tunning of the Random forest model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQkpNta00cxP"
      },
      "outputs": [],
      "source": [
        "# para_grid values to pass in gridsearchcv.\n",
        "grid_values={'n_estimators':[300, 400, 500, 700],\n",
        "          'max_depth':[None, 10, 20, 40],\n",
        "          'min_samples_split':[2,6,10],\n",
        "          'max_leaf_nodes':[None],\n",
        "          'criterion':['entropy','gini'],\n",
        "          'max_features':['auto','log2','sqrt']\n",
        "          \n",
        "             }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGRRIVlK0cxP"
      },
      "outputs": [],
      "source": [
        "# creating the instance \n",
        "rfc_= RandomForestClassifier(random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJXllUso0cxP"
      },
      "outputs": [],
      "source": [
        "# Applying GridSearchCV\n",
        "rfc_tune=GridSearchCV(rfc_,param_grid=grid_values,cv=2,verbose=3,scoring='accuracy')\n",
        "rfc_tune.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U809Vc1B0cxQ"
      },
      "outputs": [],
      "source": [
        "#Getting best paramters for the models\n",
        "rfc_tune.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7xyHyo30cxQ"
      },
      "outputs": [],
      "source": [
        "# fitting/training the data with best parameters.\n",
        "rfc_optimal=RandomForestClassifier(max_features='auto',criterion='entropy',max_depth=None,max_leaf_nodes=None,min_samples_split=6,n_estimators=700,random_state=0)\n",
        "rfc_optimal.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NINNe2zw0cxQ"
      },
      "outputs": [],
      "source": [
        "# predicting y values of train and test set.\n",
        "y_train_pred=rfc_optimal.predict(X_train)\n",
        "y_pred=rfc_optimal.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9y9D1J_P0cxQ"
      },
      "outputs": [],
      "source": [
        "# checking the train accuracy score.\n",
        "accuracy_score(y_train,y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCfxsulA0cxR"
      },
      "outputs": [],
      "source": [
        "# checking the test accuracy score.\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uih1N-MV0cxR"
      },
      "source": [
        "###**Observations of Random Forest:**\n",
        "***Before Tuning***\n",
        "* ***training accuarcy = 100%***\n",
        "* ***test accuarcy = 88%***\n",
        "\n",
        "***Model is overfitted the data and does not generalised well. So we tuned the hyperparameters.***\n",
        "***After tuning:***\n",
        "* ***Training accuarcy= 100%***\n",
        "* ***Test accuarcy = 90%***\n",
        "\n",
        "***we have slightly improved the model and overfitting is reduced slightly.***\n",
        "\n",
        "***From roc curve its clear that model has poorly performed to classify class 1 and class 2.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cei45LYG0cxR"
      },
      "source": [
        "# **3)K Nearest Neighbors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1kOwufh0cxR"
      },
      "source": [
        "### **With default hyperparametrs:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7jmizTn0cxT"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn=KNeighborsClassifier()     # creating an object of the classifier\n",
        "knn.fit(X_train_scaled,y_train)   #  fitting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrK49K8K0cxU"
      },
      "outputs": [],
      "source": [
        "# predicting the y values of train and test set.\n",
        "y_train_pred=knn.predict(X_train_scaled)\n",
        "y_pred=knn.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTExkVGe0cxU"
      },
      "outputs": [],
      "source": [
        "# checking the accuracy score of train set\n",
        "accuracy_score(y_train,y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8Dkg6bE0cxU"
      },
      "outputs": [],
      "source": [
        "# Checking the accuracy score of test set.\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAXDrHeW0cxU"
      },
      "source": [
        "### **Let's do some HyperParameter tuning.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbdjCkiu0cxV"
      },
      "outputs": [],
      "source": [
        "# creating an object of classifier\n",
        "knn=KNeighborsClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rSyOZYq0cxV"
      },
      "outputs": [],
      "source": [
        "# parameter grid values.\n",
        "grid_values = {'n_neighbors':list(range(1, 31))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wWrYlTn0cxV"
      },
      "outputs": [],
      "source": [
        "# applyong GridSearchCv with above grid values and cv=5\n",
        "knn_tune=GridSearchCV(knn,cv=5,scoring='accuracy',verbose=3,param_grid=grid_values)\n",
        "knn_tune.fit(X_train_scaled,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oe8QZ5g0cxV"
      },
      "outputs": [],
      "source": [
        "# getting thge best parameters\n",
        "knn_tune.best_params_                     # thus  best n_neighnors came out to be 29"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0X1zfsBu0cxW"
      },
      "outputs": [],
      "source": [
        "# fitting the data with best parameters\n",
        "knn_optimal=KNeighborsClassifier(n_neighbors=29)\n",
        "knn_optimal.fit(X_train_scaled,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ke_VCJO0cxW"
      },
      "outputs": [],
      "source": [
        "# predicting y values of train and test set.\n",
        "y_train_pred=knn_optimal.predict(X_train_scaled)\n",
        "y_pred=knn_optimal.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utkGzHGy0cxW"
      },
      "outputs": [],
      "source": [
        "#checking the accuracy score of train set.\n",
        "accuracy_score(y_train,y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT3S8BE_0cxW"
      },
      "outputs": [],
      "source": [
        "# checking the accuracy score of test set.\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHR_XSnL0cxX"
      },
      "source": [
        "### **Observations:**\n",
        "***Before hyperparameters tuning:***\n",
        "\n",
        "* ***Train Accuracy:75 %***\n",
        "* ***Test Accuarcy:59 %***\n",
        "\n",
        "***Clearly Model has performed very worst. We did hyperparameter tuning***\n",
        "\n",
        "***After Hyperparameter Tuning:***\n",
        "\n",
        "* ***Train Accuarcy: 77%***\n",
        "* ***Test Accuarcy: 70%***\n",
        "\n",
        "***Surely we improved the model perfromance and reduced overfitting but however this is not  good model for us.***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJstmPGZ0cxX"
      },
      "source": [
        "# **4) Support Vector Machine:** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GH0BaHL0cxX"
      },
      "source": [
        "### **with default parameters.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwTVEhma0cxX"
      },
      "outputs": [],
      "source": [
        "# Import all relevant libraries\n",
        "\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTXAo4yY0cxY"
      },
      "outputs": [],
      "source": [
        "svc = SVC(random_state=101)      # creating an object of classifier\n",
        "svc.fit(X_train_scaled,y_train)    # fitting the model/training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt80eTTq0cxY"
      },
      "outputs": [],
      "source": [
        "# predicting the y value of train set and test set\n",
        "y_train_pred=svc.predict(X_train_scaled)\n",
        "y_pred=svc.predict(X_test_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8sMYnEr0cxZ"
      },
      "outputs": [],
      "source": [
        "# Accuracy score for train set\n",
        "accuracy_score(y_train,y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7w1QiRXp0cxZ"
      },
      "outputs": [],
      "source": [
        "# Accuracy score for test set.\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5HP0QKY0cxZ"
      },
      "source": [
        "### **Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEW-XgMo0cxa"
      },
      "outputs": [],
      "source": [
        "# parameter grid for GridSearchCv\n",
        "grid_values = {\n",
        "    'C':[0.01,0.1,1,10],\n",
        "    'kernel' : [\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n",
        "    'degree' : [1,3,5,7],\n",
        "    'gamma' : [0.01,1]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKFRq5cY0cxa"
      },
      "outputs": [],
      "source": [
        "# creating an object for classifier\n",
        "svm  = SVC ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqTkPGoh0cxa"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter tuning with the GrdiSearhCV with cv=5\n",
        "svm_cv = GridSearchCV(svm, grid_values, cv = 5,verbose=2)\n",
        "svm_cv.fit(X_train_scaled,y_train)     # fitting the data into the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHJInwkm0cxb"
      },
      "outputs": [],
      "source": [
        "# getting the best parameters\n",
        "svm_cv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPW0_VhH0cxb"
      },
      "outputs": [],
      "source": [
        "# getting the best estimators\n",
        "svm_cv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCGwlEQQ0cxb"
      },
      "outputs": [],
      "source": [
        "# applying best parameters to the SVm model.\n",
        "svm_optimal=SVC(C=10, degree=1, gamma=0.01, kernel='linear',probability=True)\n",
        "svm_optimal.fit(X_train_scaled,y_train)   # fitting the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTBuFvHE0cxb"
      },
      "outputs": [],
      "source": [
        "# predicting the y values of train and test set.\n",
        "y_train_pred=svm_optimal.predict(X_train_scaled)    \n",
        "y_pred=svm_optimal.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqBu_xmk0cxc"
      },
      "outputs": [],
      "source": [
        "# checkig the accuracy score of train set.\n",
        "accuracy_score(y_train,y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJobFsq50cxc"
      },
      "outputs": [],
      "source": [
        "# checking the accuracy of test data\n",
        "accuracy_score(y_test,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YbiTtZm0cxd"
      },
      "source": [
        "### **Observations**\n",
        "\n",
        "\n",
        "* ***Accuracy score on train set is 98.5% and Test score is 89%.***\n",
        "***Model seems to be overfitted as the differance between train and test accuracy score is almot 10%.***\n",
        "* ***After Hyperparameter tuning train accuracy remained almost same  98.3% and test accuracy score increased to 97%.*** \n",
        "*  ***SVM performed very well as compared to other alogorithms.***\n",
        "* ***In terms of feature importance RAM,Battery power,px_height and px_weight are the imporatant features.***\n",
        "* ***f1 score for individual classes is also very good. Area under curve for each class prediction is also almost 1.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCX9965dhzqZ"
      },
      "source": [
        "# **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xya71v1Z0cxe"
      },
      "source": [
        "* ***We Started with Data understanding, data wrangling, basic EDA where we found the relationships, trends between price range and other independent variables.***\n",
        "* ***Implemented various classification algorithms, out of which the SVM(Support vector machine) algorithm gave the best performance after hyper-parameter tuning with 98.3% train accuracy and 97 % test accuracy.***\n",
        "* ***KNN gave very worst model performance.***\n",
        "* ***We checked for the feature importance's of each model. RAM, Battery Power, Px_height and px_width contributed the most while predicting the price range.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIfDvo9L0UH2"
      },
      "source": [
        "### ***Hurrah! We have successfully completed our Classification Capstone Project !!!***"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "KSlN3yHqYklG",
        "EM7whBJCYoAo",
        "4Of9eVA-YrdM",
        "bamQiAODYuh1",
        "OH-pJp9IphqM",
        "PIIx-8_IphqN",
        "BZR9WyysphqO",
        "YJ55k-q6phqO",
        "NC_X3p0fY2L0",
        "JcMwzZxoAimU",
        "8G2x9gOozGDZ",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "ebe6247e7a1f1167b5c64aafd6f99eb52db41c0d4edef59d26ba27c8c23c0d56"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}